{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as Data\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_EPOCH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_positions = f\"./train_labels/positions_train.npy\"\n",
    "fpath_train = f\"./train\"\n",
    "fpath_val = f\"./val\"\n",
    "fpath_test = f\"./test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_complex(X_complex):\n",
    "    fX_real = np.real(X_complex)\n",
    "    fX_imag = np.imag(X_complex)\n",
    "    fX_abs = np.abs(X_complex)\n",
    "    tX = np.fft.ifft(X_complex)\n",
    "    tX_real = np.real(tX)\n",
    "    tX_imag = np.imag(tX)\n",
    "    tX_abs = np.abs(tX)\n",
    "    return np.stack((fX_real, fX_imag, fX_abs, tX_real, tX_imag, tX_abs), axis=-1)\n",
    "\n",
    "train_files = glob.glob(f\"{fpath_train}/*.npy\")\n",
    "train_files.sort()\n",
    "\n",
    "X = np.array([process_complex(np.load(f)) for f in train_files])\n",
    "y = np.load(fpath_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_vali, y_train, y_vali = train_test_split(X, y, test_size=0.05, random_state=0)\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "X_vali = torch.Tensor(X_vali)\n",
    "y_vali = torch.Tensor(y_vali)\n",
    "\n",
    "dataset_train = Data.TensorDataset(X_train, y_train)\n",
    "\n",
    "dataloader_train = Data.DataLoader(\n",
    "    dataset = dataset_train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TransformerEncoder(100, 100, 100, 100, [64, 100], 100, 128, 10, 2, 0.1)\n",
    "decoder = get_net()\n",
    "model = EncoderDecoder(encoder, decoder)\n",
    "model = nn.DataParallel(model)\n",
    "model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "loss_fn = nn.MSELoss()\n",
    "scheduler1 = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "scheduler2 = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[32, 48], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "    return loss.item()\n",
    "\n",
    "def vali(X_vali, y_vali, model, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_vali, y_vali = X_vali.cuda(), y_vali.cuda()\n",
    "        pred = model(X_vali)\n",
    "        loss = loss_fn(pred, y_vali)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "0.030979162082076073 0.022372743114829063\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "0.03328689560294151 0.015275022014975548\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "0.010472987778484821 0.00827401876449585\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "0.00509400200098753 0.0028607617132365704\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "0.0022175454068928957 0.003935056272894144\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "0.0026633706875145435 0.0035663521848618984\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "0.0030498618725687265 0.0011291131377220154\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "0.004028420429676771 0.0017074838979169726\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "0.001729097100906074 0.0026539580430835485\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "0.0012058706488460302 0.0008049409952946007\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "0.0008325928938575089 0.0018417526734992862\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "0.0010915527818724513 0.0010932489531114697\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "0.0009254555916413665 0.0013029000256210566\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "0.0010303833987563848 0.0014379586791619658\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "0.0009906722698360682 0.001582781900651753\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "0.0006671923911198974 0.0006279399385675788\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "0.0008244246710091829 0.0007582940743304789\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "0.0006071210955269635 0.0006799510447308421\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "0.0008597189444117248 0.0007146953139454126\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "0.0005190962692722678 0.0010847598314285278\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "0.0008768393308855593 0.000920443213544786\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "0.0008633565157651901 0.0007984361727721989\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "0.00047836799058131874 0.002212574239820242\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "0.0006209532730281353 0.00036154300323687494\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "0.00020556723757181317 0.00040319314575754106\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "0.0019268929027020931 0.0008139190031215549\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "0.0006796271773055196 0.000705005950294435\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "0.0006409405032172799 0.0003193794982507825\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "0.0004159018862992525 0.0005272015114314854\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "0.00030562415486201644 0.00032059368095360696\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "0.00035664121969603 0.0002823176037054509\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "0.00022130200522951782 0.0002775560424197465\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "0.00015869224444031715 0.0002032741322182119\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "0.00019086037355009466 0.00018786323198582977\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "0.0001273193338420242 0.00018480588914826512\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "0.0001394685823470354 0.00017852842574939132\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "0.00023840430367272347 0.00017526147712487727\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "0.0002462702395860106 0.00017748121172189713\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "0.0002372431190451607 0.00018057928537018597\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "0.00010386346548330039 0.00017957165255211294\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "0.00018262400408275425 0.00017123432189691812\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "0.0002006743015954271 0.00019075987802352756\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "0.00014242911129258573 0.00016450491966679692\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "0.00021005087182857096 0.00016893120482563972\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "0.00015022045408841223 0.0001627456076676026\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "9.451954974792898e-05 0.0001695803803158924\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "0.00011514781363075599 0.00015880403225310147\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "0.00021860506967641413 0.00017054819909390062\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "0.00015537849685642868 0.00015728911967016757\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "0.00015371725021395832 0.00016186985885724425\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "0.00015170926053542644 0.0001589317835168913\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "0.0001339186856057495 0.00015844976587686688\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "0.00012204714585095644 0.0001562751567689702\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "9.538526501273736e-05 0.00015925863408483565\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "0.00015936978161334991 0.00015572394477203488\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "0.00011906484724022448 0.0001553617330500856\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "0.00013947943807579577 0.00016037783643696457\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "0.00016052703722380102 0.00015933685062918812\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "0.0001894359156722203 0.00015972930123098195\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "0.00010454144648974761 0.0001581196702318266\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "0.0005974677042104304 0.00016418240556959063\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "0.0001669546472840011 0.00016183523985091597\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "0.00016499929188285023 0.0001579833624418825\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "0.00013019562175031751 0.00015691235603298992\n"
     ]
    }
   ],
   "source": [
    "for t in range(NUM_EPOCH):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    loss_train = train(dataloader_train, model, loss_fn, optimizer)\n",
    "    loss_vali = vali(X_vali, y_vali, model, loss_fn)\n",
    "    scheduler1.step()\n",
    "    scheduler2.step()\n",
    "    print(loss_train, loss_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'model1.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_state_dict(torch.load('model1.params'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized RMSE:  0.022690907\n"
     ]
    }
   ],
   "source": [
    "truth = y_vali\n",
    "X_vali = X_vali.cuda()\n",
    "preds = model(X_vali)\n",
    "truth = truth.detach().cpu().numpy()\n",
    "preds = preds.detach().cpu().numpy()\n",
    "# You can test the logic of the scoring mechanism on Codalab here.\n",
    "#  Just be sure to keep a held-out validation set from the original training set with features and labels.\n",
    "def score(truth, preds):\n",
    "    # Compute the average positioning error between predictions and ground truth\n",
    "    rmse = np.mean(np.sqrt(np.sum((truth - preds) ** 2, axis=1)))\n",
    "    return rmse\n",
    "print(\"Standardized RMSE: \", score(truth, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading validation files from ./val...\n",
      "Done!\n",
      "torch.Size([5000, 2])\n"
     ]
    }
   ],
   "source": [
    "### Predict on validation set ###\n",
    "\n",
    "# Read CSI training files from val folder (for phase 2 of the challenge, this should be done on the test folder)\n",
    "print(f\"Reading validation files from {fpath_val}...\")\n",
    "val_files = glob.glob(f\"{fpath_val}/*.npy\")\n",
    "val_files.sort()\n",
    "\n",
    "# Load all files into a np array\n",
    "X_val = np.array([process_complex(np.load(f)) for f in val_files])\n",
    "X_val = torch.Tensor(X_val)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Predict on validation set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_val = X_val.cuda()\n",
    "    y_val_pred = model(X_val)\n",
    "print(y_val_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: preds.csv (deflated 61%)\n",
      "Predictions saved to preds.zip\n"
     ]
    }
   ],
   "source": [
    "# Save predictions to csv file in data_fpath folder and zip it.\n",
    "#  The zipped file should be used for score submission on Codalab.\n",
    "np.savetxt(f\"./preds.csv\", y_val_pred.cpu(), delimiter=\",\")\n",
    "is_written = os.system(f\"zip preds.zip preds.csv\")\n",
    "\n",
    "if ~is_written:\n",
    "    print(\"Predictions saved to preds.zip\")\n",
    "else:\n",
    "    print(\"Error while saving predictions to preds.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力\"\"\"\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # queries的形状：(batch_size，查询的个数，d)\n",
    "    # keys的形状：(batch_size，“键－值”对的个数，d)\n",
    "    # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "    def forward(self, queries, keys, values):\n",
    "        d = queries.shape[-1]\n",
    "        # 设置transpose_b=True为了交换keys的最后两个维度\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
    "        self.attention_weights = nn.functional.softmax(scores, dim=-1)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def transpose_qkv(X, num_heads):\n",
    "    \"\"\"为了多注意力头的并行计算而变换形状\"\"\"\n",
    "    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，\n",
    "    # num_hiddens/num_heads)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "\n",
    "    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,\n",
    "    # num_hiddens/num_heads)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "\n",
    "    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,\n",
    "    # num_hiddens/num_heads)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "\n",
    "#@save\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"逆转transpose_qkv函数的操作\"\"\"\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"多头注意力\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        # queries，keys，values的形状:\n",
    "        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "        # 经过变换后，输出的queries，keys，values　的形状:\n",
    "        # (batch_size*num_heads，查询或者“键－值”对的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        \n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        # output的形状:(batch_size*num_heads，查询的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        output = self.attention(queries, keys, values)\n",
    "\n",
    "        # output_concat的形状:(batch_size，查询的个数，num_hiddens)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Transformer编码器块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n",
    "            use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(\n",
    "            ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"Transformer编码器\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        # self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        # self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, use_bias))\n",
    "        # self.dense = nn.Linear(num_hiddens, 2)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        # 因为位置编码值在-1和1之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n",
    "        # 然后再与位置编码相加。\n",
    "        # X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X)\n",
    "            self.attention_weights[i] = blk.attention.attention.attention_weights\n",
    "        # X = self.dense(X.view([X.shape[0], -1]))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(input_channels, num_channels, num_residuals,\n",
    "                 first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels,\n",
    "                                use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):  #@save\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
    "                               kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
    "                               kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
    "                                   kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(input_channels, num_channels, num_residuals, first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels, use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(6, 128, kernel_size=5, stride=2, padding=3),\n",
    "                   nn.BatchNorm2d(128), nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "b2 = nn.Sequential(*resnet_block(128, 128, 2, first_block=True))\n",
    "b3 = nn.Sequential(*resnet_block(128, 64, 2))\n",
    "# b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
    "# b5 = nn.Sequential(*resnet_block(256, 512, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net():\n",
    "    net = nn.Sequential(b1, b2, b3, #b4, b5,\n",
    "                        nn.AdaptiveAvgPool2d((1,1)),\n",
    "                        nn.Flatten(), nn.Linear(64, 16), nn.ReLU(), nn.Linear(16, 2))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基类\n",
    "\n",
    "    Defined in :numref:`sec_encoder-decoder`\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        X1 = self.encoder(X[:,:,:,0], *args)\n",
    "        X2 = self.encoder(X[:,:,:,1], *args)\n",
    "        X3 = self.encoder(X[:,:,:,2], *args)\n",
    "        X4 = self.encoder(X[:,:,:,3], *args)\n",
    "        X5 = self.encoder(X[:,:,:,4], *args)\n",
    "        X6 = self.encoder(X[:,:,:,5], *args)\n",
    "        X = torch.stack((X1, X2, X3, X4, X5, X6), 1)\n",
    "        output = self.decoder(X, *args)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
