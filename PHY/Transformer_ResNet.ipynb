{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:06:21.490004Z",
     "iopub.status.busy": "2023-09-02T12:06:21.489668Z",
     "iopub.status.idle": "2023-09-02T12:06:23.977882Z",
     "shell.execute_reply": "2023-09-02T12:06:23.976954Z",
     "shell.execute_reply.started": "2023-09-02T12:06:21.489979Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as Data\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:06:26.337498Z",
     "iopub.status.busy": "2023-09-02T12:06:26.337007Z",
     "iopub.status.idle": "2023-09-02T12:06:26.342286Z",
     "shell.execute_reply": "2023-09-02T12:06:26.341275Z",
     "shell.execute_reply.started": "2023-09-02T12:06:26.337469Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:06:27.017092Z",
     "iopub.status.busy": "2023-09-02T12:06:27.016750Z",
     "iopub.status.idle": "2023-09-02T12:06:27.021687Z",
     "shell.execute_reply": "2023-09-02T12:06:27.020624Z",
     "shell.execute_reply.started": "2023-09-02T12:06:27.017068Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:06:28.810741Z",
     "iopub.status.busy": "2023-09-02T12:06:28.810296Z",
     "iopub.status.idle": "2023-09-02T12:06:28.815433Z",
     "shell.execute_reply": "2023-09-02T12:06:28.814658Z",
     "shell.execute_reply.started": "2023-09-02T12:06:28.810708Z"
    }
   },
   "outputs": [],
   "source": [
    "fpath_positions = f\"./train_labels/positions_train.npy\"\n",
    "fpath_train = f\"./train\"\n",
    "fpath_val = f\"./val\"\n",
    "fpath_test = f\"./test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:06:29.595484Z",
     "iopub.status.busy": "2023-09-02T12:06:29.594472Z",
     "iopub.status.idle": "2023-09-02T12:07:05.600493Z",
     "shell.execute_reply": "2023-09-02T12:07:05.599338Z",
     "shell.execute_reply.started": "2023-09-02T12:06:29.595452Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_complex(X_complex):\n",
    "    fX_real = np.real(X_complex)\n",
    "    fX_imag = np.imag(X_complex)\n",
    "    fX_abs = np.abs(X_complex)\n",
    "    tX = np.fft.ifft(X_complex)\n",
    "    tX_real = np.real(tX)\n",
    "    tX_imag = np.imag(tX)\n",
    "    tX_abs = np.abs(tX)\n",
    "    return np.stack((fX_real, fX_imag, fX_abs, tX_real, tX_imag, tX_abs), axis=-1)\n",
    "\n",
    "train_files = glob.glob(f\"{fpath_train}/*.npy\")\n",
    "train_files.sort()\n",
    "\n",
    "X = np.array([process_complex(np.load(f)) for f in train_files])\n",
    "y = np.load(fpath_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:08.051288Z",
     "iopub.status.busy": "2023-09-02T12:07:08.050869Z",
     "iopub.status.idle": "2023-09-02T12:07:18.574801Z",
     "shell.execute_reply": "2023-09-02T12:07:18.574026Z",
     "shell.execute_reply.started": "2023-09-02T12:07:08.051259Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_vali, y_train, y_vali = train_test_split(X, y, test_size=0.05, random_state=0)\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "X_vali = torch.Tensor(X_vali)\n",
    "y_vali = torch.Tensor(y_vali)\n",
    "\n",
    "dataset_train = Data.TensorDataset(X_train, y_train)\n",
    "\n",
    "dataloader_train = Data.DataLoader(\n",
    "    dataset = dataset_train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:30.926387Z",
     "iopub.status.busy": "2023-09-02T12:07:30.926038Z",
     "iopub.status.idle": "2023-09-02T12:07:33.066300Z",
     "shell.execute_reply": "2023-09-02T12:07:33.065302Z",
     "shell.execute_reply.started": "2023-09-02T12:07:30.926361Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = TransformerEncoder(100, 100, 100, 100, [64, 100], 100, 512, 10, 2, 0.1)\n",
    "decoder = get_net()\n",
    "model = EncoderDecoder(encoder, decoder)\n",
    "model = nn.DataParallel(model)\n",
    "model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "loss_fn = nn.MSELoss()\n",
    "scheduler1 = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "scheduler2 = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 60, 90], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:34.489606Z",
     "iopub.status.busy": "2023-09-02T12:07:34.488952Z",
     "iopub.status.idle": "2023-09-02T12:07:34.495135Z",
     "shell.execute_reply": "2023-09-02T12:07:34.494313Z",
     "shell.execute_reply.started": "2023-09-02T12:07:34.489576Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "    return loss.item()\n",
    "\n",
    "def vali(X_vali, y_vali, model, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_vali, y_vali = X_vali.cuda(), y_vali.cuda()\n",
    "        pred = model(X_vali)\n",
    "        loss = loss_fn(pred, y_vali)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:35.836727Z",
     "iopub.status.busy": "2023-09-02T12:07:35.835636Z",
     "iopub.status.idle": "2023-09-02T12:27:50.112402Z",
     "shell.execute_reply": "2023-09-02T12:27:50.109581Z",
     "shell.execute_reply.started": "2023-09-02T12:07:35.836694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "0.06249457597732544 0.2607347071170807\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "0.013473959639668465 0.013875218108296394\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "0.015043488703668118 0.0043165963143110275\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "0.03878200054168701 0.0087971156463027\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "0.002234164159744978 0.006485289894044399\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "0.006021357607096434 0.014093856327235699\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "0.008905479684472084 0.015723034739494324\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "0.00871986709535122 0.00316994683817029\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "0.0028209583833813667 0.007677080575376749\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "0.0011253532720729709 0.001955917105078697\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "0.0017364221857860684 0.0015775476349517703\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "0.0022195284254848957 0.0018012167420238256\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "0.0011540844570845366 0.001061548013240099\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "0.0006693968898616731 0.002108457498252392\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "0.0007371458923444152 0.0017207596683874726\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "0.0005545744206756353 0.000799364410340786\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "0.0012826330494135618 0.0009639604832045734\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "0.0008980066049844027 0.0018963204929605126\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "0.0008588784839957952 0.0007641573902219534\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "0.0007030653650872409 0.00044890347635373473\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "0.0007432122947648168 0.001223564031533897\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "0.0015124226920306683 0.0006294380291365087\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "0.0005646836943924427 0.00046899545122869313\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "0.0006000815774314106 0.0007346654892899096\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "0.0003782418498303741 0.0004371784161776304\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "0.0005783053929917514 0.000843414047267288\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "0.0003726571740116924 0.00040258787339553237\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "0.0005184815963730216 0.0005464390851557255\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "0.0004923027590848505 0.00041056692134588957\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "0.00031070044497027993 0.0003229469293728471\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "0.00018255495524499565 0.0002240829635411501\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "0.0001713377860141918 0.00029378861654549837\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "0.0002333449083380401 0.0002045140281552449\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "0.00018530113447923213 0.0002118908887496218\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "0.00020402403606567532 0.0002653060364536941\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "0.00016545652761124074 0.00020322769705671817\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "0.0003456704143900424 0.00021161040058359504\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "0.00018831901252269745 0.0002320463245268911\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "0.00014905208081472665 0.00020294896967243403\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "0.00021090560767333955 0.00020752925775013864\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "0.00028188677970319986 0.00018750285380519927\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "0.0001977070205612108 0.00020103820133954287\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "0.00019957883341703564 0.00016281571879517287\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "0.00013862428022548556 0.0001773562835296616\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "0.00012593669816851616 0.00017597842088434845\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "0.00019959382188972086 0.00018510142399463803\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "0.00015387547318823636 0.00021920792642049491\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "0.00017537739768158644 0.00017655815463513136\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "0.00022457708837464452 0.0001704651367617771\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "0.0001364745112368837 0.00019127952691633254\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "0.00014798094343859702 0.0001646574673941359\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "0.00012563032214529812 0.00019243796123191714\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "0.0001901521027320996 0.00017503714479971677\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "0.00015537740546278656 0.000165365549037233\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "0.00013086505350656807 0.0001826957450248301\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "0.00016324332682415843 0.0001571535540279001\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "0.0002564149326644838 0.0001853345602285117\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "9.367985330754891e-05 0.00019037473248317838\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "0.00018360941612627357 0.00016062968643382192\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "0.00017406106053385884 0.0001738515420584008\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "0.00022795172117184848 0.00016452278941869736\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "0.00015297751815523952 0.00016200503159780055\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "0.00011267331137787551 0.0001726082991808653\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "0.00015033005911391228 0.00016652517660986632\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "0.00018902057490777224 0.00016727657930459827\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "0.0001917685440275818 0.0001736623962642625\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "0.00016199318633880466 0.00016582859097979963\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "0.00015071204688865691 0.000169575258041732\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "0.00011027227446902543 0.0001674116065260023\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "0.00018393014033790678 0.00015896238619461656\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "0.00015923104365356266 0.00017010595183819532\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "0.00016013307322282344 0.00017781750648282468\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "0.0001428200921509415 0.00016426622460130602\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "0.00013272243086248636 0.0001688995398581028\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "0.0001240865676663816 0.00016861002950463444\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "0.00010120989463757724 0.00016973762831185013\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "0.00011541808635229245 0.0001605035795364529\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "0.0001303947065025568 0.0001698506239335984\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "0.000131946086185053 0.00015893325326032937\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "9.372515341965482e-05 0.0001674845552770421\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "0.00012745986168738455 0.00016993997269310057\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "0.00012359675019979477 0.0001733451063046232\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "0.00013102818047627807 0.00016094287275336683\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "0.00023090795730240643 0.0001707082992652431\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "0.00013376840797718614 0.00017990541527979076\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "0.00013652027701027691 0.00016492436407133937\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "0.00016774215328041464 0.00017531147750560194\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "0.00013436074368655682 0.0001701733999652788\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "9.437940025236458e-05 0.0001609406026545912\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "0.00011733597057173029 0.00016484438674524426\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "0.00027026949101127684 0.00016703001165296882\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "0.00015341750986408442 0.0001728670613374561\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "0.00019081312348134816 0.00017693720292299986\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "0.0001754260592861101 0.00016750172653701156\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "0.00012899957073386759 0.00016735706594772637\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "0.000136021597427316 0.00016382228932343423\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "0.00014340369671117514 0.00016530623543076217\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "0.00013490710989572108 0.00016892273561097682\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "0.00010289257625117898 0.0001653728832025081\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "0.00019695916853379458 0.0001843765494413674\n"
     ]
    }
   ],
   "source": [
    "for t in range(NUM_EPOCH):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    loss_train = train(dataloader_train, model, loss_fn, optimizer)\n",
    "    loss_vali = vali(X_vali, y_vali, model, loss_fn)\n",
    "    scheduler1.step()\n",
    "    scheduler2.step()\n",
    "    print(loss_train, loss_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:02:58.047161Z",
     "iopub.status.busy": "2023-08-30T11:02:58.045981Z",
     "iopub.status.idle": "2023-08-30T11:02:58.091276Z",
     "shell.execute_reply": "2023-08-30T11:02:58.090472Z",
     "shell.execute_reply.started": "2023-08-30T11:02:58.047107Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model-512.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model-512.params'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:02:59.707025Z",
     "iopub.status.busy": "2023-08-30T11:02:59.706677Z",
     "iopub.status.idle": "2023-08-30T11:02:59.902625Z",
     "shell.execute_reply": "2023-08-30T11:02:59.901840Z",
     "shell.execute_reply.started": "2023-08-30T11:02:59.707001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized RMSE:  0.012033874\n"
     ]
    }
   ],
   "source": [
    "truth = y_vali\n",
    "X_vali = X_vali.cuda()\n",
    "preds = model(X_vali)\n",
    "truth = truth.detach().cpu().numpy()\n",
    "preds = preds.detach().cpu().numpy()\n",
    "# You can test the logic of the scoring mechanism on Codalab here.\n",
    "#  Just be sure to keep a held-out validation set from the original training set with features and labels.\n",
    "def score(truth, preds):\n",
    "    # Compute the average positioning error between predictions and ground truth\n",
    "    rmse = np.mean(np.sqrt(np.sum((truth - preds) ** 2, axis=1)))\n",
    "    return rmse\n",
    "print(\"Standardized RMSE: \", score(truth, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:03:02.664808Z",
     "iopub.status.busy": "2023-08-30T11:03:02.664402Z",
     "iopub.status.idle": "2023-08-30T11:03:07.068623Z",
     "shell.execute_reply": "2023-08-30T11:03:07.067878Z",
     "shell.execute_reply.started": "2023-08-30T11:03:02.664778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading validation files from ./test...\n",
      "Done!\n",
      "torch.Size([5000, 2])\n"
     ]
    }
   ],
   "source": [
    "### Predict on validation set ###\n",
    "\n",
    "# Read CSI training files from val folder (for phase 2 of the challenge, this should be done on the test folder)\n",
    "print(f\"Reading validation files from {fpath_test}...\")\n",
    "val_files = glob.glob(f\"{fpath_test}/*.npy\")\n",
    "val_files.sort()\n",
    "\n",
    "# Load all files into a np array\n",
    "X_val = np.array([process_complex(np.load(f)) for f in val_files])\n",
    "X_val = torch.Tensor(X_val)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Predict on validation set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_val = X_val.cuda()\n",
    "    y_val_pred = model(X_val)\n",
    "print(y_val_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:03:08.156230Z",
     "iopub.status.busy": "2023-08-30T11:03:08.155849Z",
     "iopub.status.idle": "2023-08-30T11:03:08.242666Z",
     "shell.execute_reply": "2023-08-30T11:03:08.241863Z",
     "shell.execute_reply.started": "2023-08-30T11:03:08.156203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: preds.csv (deflated 61%)\n",
      "Predictions saved to preds.zip\n"
     ]
    }
   ],
   "source": [
    "# Save predictions to csv file in data_fpath folder and zip it.\n",
    "#  The zipped file should be used for score submission on Codalab.\n",
    "np.savetxt(f\"./preds.csv\", y_val_pred.cpu(), delimiter=\",\")\n",
    "is_written = os.system(f\"zip preds.zip preds.csv\")\n",
    "\n",
    "if ~is_written:\n",
    "    print(\"Predictions saved to preds.zip\")\n",
    "else:\n",
    "    print(\"Error while saving predictions to preds.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:22.283072Z",
     "iopub.status.busy": "2023-09-02T12:07:22.282075Z",
     "iopub.status.idle": "2023-09-02T12:07:22.288775Z",
     "shell.execute_reply": "2023-09-02T12:07:22.287802Z",
     "shell.execute_reply.started": "2023-09-02T12:07:22.283031Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:22.521997Z",
     "iopub.status.busy": "2023-09-02T12:07:22.521397Z",
     "iopub.status.idle": "2023-09-02T12:07:22.526971Z",
     "shell.execute_reply": "2023-09-02T12:07:22.526076Z",
     "shell.execute_reply.started": "2023-09-02T12:07:22.521969Z"
    }
   },
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:22.699411Z",
     "iopub.status.busy": "2023-09-02T12:07:22.698756Z",
     "iopub.status.idle": "2023-09-02T12:07:22.704784Z",
     "shell.execute_reply": "2023-09-02T12:07:22.704061Z",
     "shell.execute_reply.started": "2023-09-02T12:07:22.699379Z"
    }
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力\"\"\"\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # queries的形状：(batch_size，查询的个数，d)\n",
    "    # keys的形状：(batch_size，“键－值”对的个数，d)\n",
    "    # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "    def forward(self, queries, keys, values):\n",
    "        d = queries.shape[-1]\n",
    "        # 设置transpose_b=True为了交换keys的最后两个维度\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
    "        self.attention_weights = nn.functional.softmax(scores, dim=-1)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:22.905656Z",
     "iopub.status.busy": "2023-09-02T12:07:22.905142Z",
     "iopub.status.idle": "2023-09-02T12:07:22.910958Z",
     "shell.execute_reply": "2023-09-02T12:07:22.910251Z",
     "shell.execute_reply.started": "2023-09-02T12:07:22.905627Z"
    }
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "def transpose_qkv(X, num_heads):\n",
    "    \"\"\"为了多注意力头的并行计算而变换形状\"\"\"\n",
    "    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，\n",
    "    # num_hiddens/num_heads)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "\n",
    "    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,\n",
    "    # num_hiddens/num_heads)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "\n",
    "    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,\n",
    "    # num_hiddens/num_heads)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "\n",
    "#@save\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"逆转transpose_qkv函数的操作\"\"\"\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:23.100228Z",
     "iopub.status.busy": "2023-09-02T12:07:23.099553Z",
     "iopub.status.idle": "2023-09-02T12:07:23.107102Z",
     "shell.execute_reply": "2023-09-02T12:07:23.106350Z",
     "shell.execute_reply.started": "2023-09-02T12:07:23.100199Z"
    }
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"多头注意力\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        # queries，keys，values的形状:\n",
    "        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "        # 经过变换后，输出的queries，keys，values　的形状:\n",
    "        # (batch_size*num_heads，查询或者“键－值”对的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        \n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        # output的形状:(batch_size*num_heads，查询的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        output = self.attention(queries, keys, values)\n",
    "\n",
    "        # output_concat的形状:(batch_size，查询的个数，num_hiddens)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:23.337600Z",
     "iopub.status.busy": "2023-09-02T12:07:23.337237Z",
     "iopub.status.idle": "2023-09-02T12:07:23.344359Z",
     "shell.execute_reply": "2023-09-02T12:07:23.343191Z",
     "shell.execute_reply.started": "2023-09-02T12:07:23.337574Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Transformer编码器块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n",
    "            use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(\n",
    "            ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:23.534659Z",
     "iopub.status.busy": "2023-09-02T12:07:23.533741Z",
     "iopub.status.idle": "2023-09-02T12:07:23.541454Z",
     "shell.execute_reply": "2023-09-02T12:07:23.540455Z",
     "shell.execute_reply.started": "2023-09-02T12:07:23.534635Z"
    }
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"Transformer编码器\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        # self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        # self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, use_bias))\n",
    "        # self.dense = nn.Linear(num_hiddens, 2)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        # 因为位置编码值在-1和1之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n",
    "        # 然后再与位置编码相加。\n",
    "        # X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X)\n",
    "            self.attention_weights[i] = blk.attention.attention.attention_weights\n",
    "        # X = self.dense(X.view([X.shape[0], -1]))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:23.737099Z",
     "iopub.status.busy": "2023-09-02T12:07:23.736486Z",
     "iopub.status.idle": "2023-09-02T12:07:23.741841Z",
     "shell.execute_reply": "2023-09-02T12:07:23.741055Z",
     "shell.execute_reply.started": "2023-09-02T12:07:23.737099Z"
    }
   },
   "outputs": [],
   "source": [
    "def resnet_block(input_channels, num_channels, num_residuals,\n",
    "                 first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels,\n",
    "                                use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:23.966648Z",
     "iopub.status.busy": "2023-09-02T12:07:23.966021Z",
     "iopub.status.idle": "2023-09-02T12:07:23.974766Z",
     "shell.execute_reply": "2023-09-02T12:07:23.973822Z",
     "shell.execute_reply.started": "2023-09-02T12:07:23.966608Z"
    }
   },
   "outputs": [],
   "source": [
    "class Residual(nn.Module):  #@save\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
    "                               kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
    "                               kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
    "                                   kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:24.185296Z",
     "iopub.status.busy": "2023-09-02T12:07:24.184811Z",
     "iopub.status.idle": "2023-09-02T12:07:24.190803Z",
     "shell.execute_reply": "2023-09-02T12:07:24.189845Z",
     "shell.execute_reply.started": "2023-09-02T12:07:24.185268Z"
    }
   },
   "outputs": [],
   "source": [
    "def resnet_block(input_channels, num_channels, num_residuals, first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels, use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:24.473606Z",
     "iopub.status.busy": "2023-09-02T12:07:24.472982Z",
     "iopub.status.idle": "2023-09-02T12:07:24.505542Z",
     "shell.execute_reply": "2023-09-02T12:07:24.504631Z",
     "shell.execute_reply.started": "2023-09-02T12:07:24.473578Z"
    }
   },
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(6, 128, kernel_size=5, stride=2, padding=3),\n",
    "                   nn.BatchNorm2d(128), nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "b2 = nn.Sequential(*resnet_block(128, 128, 2, first_block=True))\n",
    "b3 = nn.Sequential(*resnet_block(128, 64, 2))\n",
    "# b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
    "# b5 = nn.Sequential(*resnet_block(256, 512, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:25.321096Z",
     "iopub.status.busy": "2023-09-02T12:07:25.320750Z",
     "iopub.status.idle": "2023-09-02T12:07:25.326147Z",
     "shell.execute_reply": "2023-09-02T12:07:25.325090Z",
     "shell.execute_reply.started": "2023-09-02T12:07:25.321070Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_net():\n",
    "    net = nn.Sequential(b1, b2, b3, #b4, b5,\n",
    "                        nn.AdaptiveAvgPool2d((1,1)),\n",
    "                        nn.Flatten(), nn.Linear(64, 16), nn.ReLU(), nn.Linear(16, 2))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T12:07:25.967225Z",
     "iopub.status.busy": "2023-09-02T12:07:25.966690Z",
     "iopub.status.idle": "2023-09-02T12:07:25.973737Z",
     "shell.execute_reply": "2023-09-02T12:07:25.972810Z",
     "shell.execute_reply.started": "2023-09-02T12:07:25.967195Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基类\n",
    "\n",
    "    Defined in :numref:`sec_encoder-decoder`\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        X1 = self.encoder(X[:,:,:,0], *args)\n",
    "        X2 = self.encoder(X[:,:,:,1], *args)\n",
    "        X3 = self.encoder(X[:,:,:,2], *args)\n",
    "        X4 = self.encoder(X[:,:,:,3], *args)\n",
    "        X5 = self.encoder(X[:,:,:,4], *args)\n",
    "        X6 = self.encoder(X[:,:,:,5], *args)\n",
    "        X = torch.stack((X1, X2, X3, X4, X5, X6), 1)\n",
    "        output = self.decoder(X, *args)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
